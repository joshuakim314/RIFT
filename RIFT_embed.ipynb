{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/josh/IAQF2023/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-23 02:36:37 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import dill\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "from modules.RIFT_dataset import RIFT_Dataset\n",
    "from modules.RIFT_model import RIFT_Model\n",
    "from modules.RIFT_model_config import RIFT_Model_Config\n",
    "from modules.train_model import Model_Trainer\n",
    "from modules.radam import RAdam\n",
    "from modules.train_utils import ret_seq_indices, shifted_diff, ts_moving_average, ts_moving_var, seq_corr_1d, seq_corr_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_ts_transform_list():\n",
    "    input_ts_transform_list = []\n",
    "    input_ts_transform_list.append(ret_seq_indices)\n",
    "    for i in range(1, 11):\n",
    "        def f_shifted_diff(x, i=i): return shifted_diff(x, i)\n",
    "        input_ts_transform_list.append(f_shifted_diff)\n",
    "    for i in range(10, 200, 20):\n",
    "        def f_moving_avg(x, i=i): return ts_moving_average(x, i)\n",
    "        input_ts_transform_list.append(f_moving_avg)\n",
    "        def f_moving_var(x, i=i): return ts_moving_var(x, i)\n",
    "        input_ts_transform_list.append(f_moving_var)\n",
    "    return input_ts_transform_list\n",
    "\n",
    "\n",
    "input_ts_transform_fns = get_input_ts_transform_list()\n",
    "target_fns = [\n",
    "    lambda x1, x2: seq_corr_1d(x1, x2),\n",
    "    lambda x1, x2: seq_corr_1d(x1[0:120], x2[0:120]),\n",
    "    lambda x1, x2: seq_corr_1d(x1[0:60], x2[0:60]),\n",
    "    lambda x1, x2: seq_corr_1d(x1[0:20], x2[0:20]),\n",
    "    lambda x1, x2: seq_corr_1d(x1[0:10], x2[0:10]),\n",
    "    lambda x1, x2: seq_corr_1d(x1[0:5], x2[0:5])\n",
    "]\n",
    "\n",
    "DAYS_LAG = 500\n",
    "DAYS_LEAD = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_df = pd.read_csv(\"data/ts_df/ts_df.csv\", encoding='utf-8')\n",
    "dates = ['2017-01-03', '2018-01-02', '2019-01-02', '2020-01-02', '2021-01-04', '2022-01-03']\n",
    "embed_sets = [RIFT_Dataset(ts_df, (date, date), target_fns=target_fns, days_lag=DAYS_LAG, days_lead=DAYS_LEAD, sample_size=\"ALL\") for date in dates]\n",
    "with open('data/embed/embed_sets.dill', 'wb') as handle:\n",
    "    dill.dump(embed_sets, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final size of concatenated embeddings within the encoder is: 950\n"
     ]
    }
   ],
   "source": [
    "best_model_id = '8e7ca76ba73e4bcdb646329e72817438'\n",
    "with open(f'mlruns/{best_model_id}/config.dill', 'rb') as handle:\n",
    "    config = dill.load(handle)\n",
    "\n",
    "model = RIFT_Model(config)\n",
    "model.load_state_dict(torch.load(f\"mlruns/{best_model_id}/model.pth\"))\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_to_numpy(tensor):\n",
    "    return(tensor.detach().cpu().numpy())\n",
    "\n",
    "\n",
    "def get_embed(model, embed_set, batch_size=64):\n",
    "    model.eval()\n",
    "    embed_dict = dict()\n",
    "\n",
    "    embed_loader = data.DataLoader(embed_set, batch_size=batch_size, drop_last=False, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(embed_loader):\n",
    "            date, rel_date_num, t, s = labels\n",
    "            print(f\"{i}: {date[0]}, {t}\")\n",
    "            for j in range(len(t)):\n",
    "                embed_dict[t[j]] = torch_to_numpy(model.siamese_encoder.encoder_forward(inputs[0])[0][j])\n",
    "    \n",
    "    embed_df = pd.DataFrame.from_dict(embed_dict)\n",
    "    return embed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, embed_set in enumerate(embed_sets):\n",
    "    embed_df = get_embed(model, embed_set)\n",
    "    embed_df.to_csv(f\"data/embed/{dates[i]}.csv\", encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1dbd705d0f249f6a0ad00411555f188c9355f16425fe59284c2b8e28c7451a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
